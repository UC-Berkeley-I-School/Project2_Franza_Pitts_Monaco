{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Project 2 - \n",
    "_______\n",
    "\n",
    "### Data Description\n",
    "These data provide a window into how people are interacting with the government online. The data come from a unified Google Analytics account for U.S. federal government agencies known as the Digital Analytics Program. This program helps government agencies understand how people find, access, and use government services online. The program does not track individuals, and anonymizes the IP addresses of visitors.\n",
    "\n",
    "Not every government website is represented in these data. Currently, the Digital Analytics Program collects web traffic from around 400 executive branch government domains, across about 5,700 total websites, including every cabinet department. We continue to pursue and add more sites frequently; to add your site, email the Digital Analytics Program."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question and Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Goals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition\n",
    "**Background**\n",
    "\n",
    "One of the challenges of this project was acquiring data.  The original dataset we prospected was found to be corrupted. \n",
    "After looking at the data, we found that the there were so many errors, it would have been nearly impossible to complete the project as planned.\n",
    "\n",
    "**Error Source** \n",
    "\n",
    "The data was corrupted by human error.  The developers who maintain the dataset, allowed synthetic data to contaminate the downloadable `.csv` files they make available to the public.  Over half of the observations contained website domains such as www.fakesite.com.  \n",
    "\n",
    "**Solution**\n",
    "\n",
    "Instead of waiting for the data errors to be fixed and run the risk of having incomplete data for our project, we decided to proceed with acquiring data through the API.  We did need to adjust our initial data questions as the API is still in BETA and did not have the same headers available as the `.csv` files.  Where we did lose some variable information, we did gain the ability to acquire time-series data, which was not available in the original dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_to_parquet(agencies: Sequence[str], reports: Sequence[str], api_key: str, response_limit=1000) -> None:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        agencies (Sequence[str]): _description_\n",
    "        reports (Sequence[str]): _description_\n",
    "        api_key (str): _description_\n",
    "        response_limit (int, optional): _description_. Defaults to 1000.\n",
    "    \"\"\"\n",
    "    start_date = datetime.datetime.strptime('2020-03-01', '%Y-%m-%d')\n",
    "    end_date = datetime.datetime.strptime('2020-03-31', '%Y-%m-%d')\n",
    "    increment_days = 30\n",
    "    \n",
    "    num_periods = ((datetime.datetime.now() - start_date).days + 1) // increment_days\n",
    "    \n",
    "    # Loop through the reports.\n",
    "    for report in reports:\n",
    "        new_dataframe = pd.DataFrame()\n",
    "        # Loop through the agencies.\n",
    "        for agency in agencies:\n",
    "            print(f\"I'm on {report}/{agency}\")\n",
    "            # Create the URL for the API call.\n",
    "            url = f\"https://api.gsa.gov/analytics/dap/v1.1/agencies/{agency}/reports/{report}/data?api_key={api_key}\"\n",
    "            with tqdm(total=num_periods) as pbar:\n",
    "                # Loop through the date range.\n",
    "                while start_date < datetime.datetime.now():\n",
    "                    \n",
    "                    # Add the date range parameters to the URL and increment the dates by 1 day.\n",
    "                    url_date_params = f\"&after={start_date.strftime('%Y-%m-%d')}&before={end_date.strftime('%Y-%m-%d')}&limit={response_limit}\"\n",
    "                    full_url = url + url_date_params\n",
    "\n",
    "                    response = requests.get(full_url).json() # api call\n",
    "                    response = pd.DataFrame(response) # make the json response a dataframe.\n",
    "\n",
    "                    # Concatenate the new data to the existing dataframe.\n",
    "                    new_dataframe = pd.concat([new_dataframe, response])\n",
    "                    \n",
    "                    # Increment the dates by the specified number of days.\n",
    "                    start_date += datetime.timedelta(days=increment_days)\n",
    "                    end_date += datetime.timedelta(days=increment_days)\n",
    "                    \n",
    "                    # Update progress bar.\n",
    "                    pbar.update(1)\n",
    "            start_date = datetime.datetime.strptime('2020-01-01', '%Y-%m-%d')\n",
    "            end_date = datetime.datetime.strptime('2020-03-31', '%Y-%m-%d')\n",
    "            \n",
    "            print(full_url)            \n",
    "        new_dataframe['date'] = pd.to_datetime(new_dataframe['date'])\n",
    "\n",
    "        # write to parquet file to the data folder.\n",
    "        new_dataframe.to_parquet(f\"./data/{report}_report_all_agencies.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_agencies = ['energy', 'health-human-services', \n",
    "                    'office-personnel-management', 'postal-service', \n",
    "                    'small-business-administration', 'social-security-administration',\n",
    "                    'state', 'transportation',\n",
    "                    'treasury', 'commerce', 'agency-international-development']\n",
    "list_of_reports = ['second-level-domain','language']\n",
    "\n",
    "# api key \n",
    "api_key = 'replace_with_your_api_key'\n",
    "\n",
    "# call the function\n",
    "api_to_parquet(list_of_agencies, list_of_reports, api_key, response_limit=1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "(observations & notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 392525 entries, 0 to 5\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   id             392525 non-null  int64         \n",
      " 1   date           392525 non-null  datetime64[ns]\n",
      " 2   report_name    392525 non-null  object        \n",
      " 3   report_agency  392525 non-null  object        \n",
      " 4   domain         392525 non-null  object        \n",
      " 5   visits         392525 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "pdf1 = pd.read_parquet('./data/site_report_all_agencies.parquet')\n",
    "pdf1.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View and Describe Data\n",
    "(observations & notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "\"id\": 123561668,\n",
    "\"date\": \"2023-04-12\",\n",
    "\"report_name\": \"download\",\n",
    "\"report_agency\": null,\n",
    "\"page\": \"irs.gov/forms-pubs/about-form-4868\",\n",
    "\"page_title\": \"About Form 4868, Application for Automatic Extension of Time to File U.S. Individual Income Tax Return | Internal Revenue Service\",\n",
    "\"event_label\": \"https://www.irs.gov/pub/irs-pdf/f4868.pdf\",\n",
    "\"total_events\": 48266\n",
    "},\n",
    "{\n",
    "\"id\": 123591100,\n",
    "\"date\": \"2023-04-12\",\n",
    "\"report_name\": \"site\",\n",
    "\"report_agency\": \"agency-international-development\",\n",
    "\"domain\": \"usaid.gov\",\n",
    "\"visits\": 42902\n",
    "},\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
